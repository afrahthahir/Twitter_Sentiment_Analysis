{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bbe147d-5b56-4527-9664-fcc64ff86297",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# To remove the warnings\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore') \n",
    "warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bfe385c",
   "metadata": {},
   "source": [
    "## Necessary imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e9c65c30-7516-446f-8c49-bdb82dc1e2a2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-05 08:11:06.250658: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-10-05 08:11:06.250779: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-10-05 08:11:06.252347: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-10-05 08:11:06.262407: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-10-05 08:11:07.412206: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from transformers import TFDistilBertForSequenceClassification, DistilBertTokenizerFast\n",
    "from tensorflow.keras.layers import Input, Dense, Dropout\n",
    "from tensorflow.keras.models import Model\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f90374c",
   "metadata": {},
   "source": [
    "## Hyperparameters "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "125457ee-ce66-45eb-9d02-ab57383a9803",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# HYPERPARAMETERS\n",
    "# Task-specific parameters\n",
    "\n",
    "NUM_LABELS = 2           # Based on your expected sentiment classes (e.g., Positive, Negative)\n",
    "MODEL_NAME = \"distilbert-base-uncased\" # DistilBERT model as it is lighter and faster than BERT\n",
    "BATCH_SIZE = 32\n",
    "LEARNING_RATE = 1e-4       # Typical learning rate for fine-tuning transformers, reduced for frozen weights training\n",
    "EPOCHS = 20                # Number of training epochs\n",
    "DROPOUT_RATE = 0.4     # Standard dropout rate\n",
    "PATIENCE = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f83e71b",
   "metadata": {},
   "source": [
    "## Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d55377e1-2bf9-4ca7-a790-75f21ebfb6c2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(74682, 4)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"twitter_training.csv\") # Load the dataset for training\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dcbb7ee7-f3d0-4a52-8e3d-d4ea752c92ab",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweet ID</th>\n",
       "      <th>entity</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>Tweet content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2401</td>\n",
       "      <td>Borderlands</td>\n",
       "      <td>Positive</td>\n",
       "      <td>im getting on borderlands and i will murder yo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2401</td>\n",
       "      <td>Borderlands</td>\n",
       "      <td>Positive</td>\n",
       "      <td>I am coming to the borders and I will kill you...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2401</td>\n",
       "      <td>Borderlands</td>\n",
       "      <td>Positive</td>\n",
       "      <td>im getting on borderlands and i will kill you ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2401</td>\n",
       "      <td>Borderlands</td>\n",
       "      <td>Positive</td>\n",
       "      <td>im coming on borderlands and i will murder you...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2401</td>\n",
       "      <td>Borderlands</td>\n",
       "      <td>Positive</td>\n",
       "      <td>im getting on borderlands 2 and i will murder ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Tweet ID       entity sentiment  \\\n",
       "0      2401  Borderlands  Positive   \n",
       "1      2401  Borderlands  Positive   \n",
       "2      2401  Borderlands  Positive   \n",
       "3      2401  Borderlands  Positive   \n",
       "4      2401  Borderlands  Positive   \n",
       "\n",
       "                                       Tweet content  \n",
       "0  im getting on borderlands and i will murder yo...  \n",
       "1  I am coming to the borders and I will kill you...  \n",
       "2  im getting on borderlands and i will kill you ...  \n",
       "3  im coming on borderlands and i will murder you...  \n",
       "4  im getting on borderlands 2 and i will murder ...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a761fc9-60e7-4204-b768-1b7030b16078",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Tweet ID           0\n",
       "entity             0\n",
       "sentiment          0\n",
       "Tweet content    686\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum() # Null values in the dataset is 686"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9edf509d-9662-43fb-af8d-36804cbd3465",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df1 = df.dropna(axis=0) # Dropping the null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6d7fb82e-4e53-41c7-bdc8-d888e02616db",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(73996, 4)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "eb75ebbf-eec2-4861-b995-616594b76789",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sentiment\n",
       "Negative      22358\n",
       "Positive      20655\n",
       "Neutral       18108\n",
       "Irrelevant    12875\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1['sentiment'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a3d3a65-f221-4559-9d51-8fabf7854f4a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>Tweet content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Positive</td>\n",
       "      <td>im getting on borderlands and i will murder yo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Positive</td>\n",
       "      <td>I am coming to the borders and I will kill you...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Positive</td>\n",
       "      <td>im getting on borderlands and i will kill you ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Positive</td>\n",
       "      <td>im coming on borderlands and i will murder you...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Positive</td>\n",
       "      <td>im getting on borderlands 2 and i will murder ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  sentiment                                      Tweet content\n",
       "0  Positive  im getting on borderlands and i will murder yo...\n",
       "1  Positive  I am coming to the borders and I will kill you...\n",
       "2  Positive  im getting on borderlands and i will kill you ...\n",
       "3  Positive  im coming on borderlands and i will murder you...\n",
       "4  Positive  im getting on borderlands 2 and i will murder ..."
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2 = df1.drop(columns=[\"Tweet ID\", \"entity\"], axis=1)  # Dropping unnecessary columns\n",
    "\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09977383-68be-4ba7-a2de-006250f853c4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Drop the 'Irrelevant' Class\n",
    "df3 = df2[df2['sentiment'] != 'Irrelevant'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36c18c77-9cfd-4ef8-b7c7-27623db9eabd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Drop the 'Neutral' Class\n",
    "df4 = df3[df3['sentiment'] != 'Neutral'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d29886df-d7b9-4a99-ae62-e24dd1bcbb50",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sentiment\n",
       "Negative    22358\n",
       "Positive    20655\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df4[\"sentiment\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ddf79e9-538c-4087-bd98-321c2099e00d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Encode the sentiment labels to numerical values\n",
    "df4[\"sentiment\"].replace({  \n",
    "    \"Negative\": 0,\n",
    "    \"Positive\": 1\n",
    "},\n",
    "inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3385b64f-1822-49fa-ac3f-d76edcbcb47c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "# --- 1. Noise Removal Function ---\n",
    "def clean_tweet_text(text):\n",
    "    # Remove URLs/Links (http, https, www, pic.twitter.com)\n",
    "    text = re.sub(r'http\\S+|www\\S+|pic\\.twitter\\.com\\S+', '', text, flags=re.MULTILINE)\n",
    "    # Remove Twitter Handles (@username)\n",
    "    text = re.sub(r'@\\w+', '', text)\n",
    "    # Remove Retweet tags (if any)\n",
    "    text = re.sub(r'RT\\s+', '', text)\n",
    "    # Remove extra whitespace\n",
    "    text = ' '.join(text.split()).strip()\n",
    "    return text\n",
    "\n",
    "# Apply the cleaning function\n",
    "df4['cleaned_content'] = df4['Tweet content'].apply(clean_tweet_text)\n",
    "df4.drop(['Tweet content'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "622ccf87-980a-424f-adae-199c96d98006",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>cleaned_content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>im getting on borderlands and i will murder yo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>I am coming to the borders and I will kill you...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>im getting on borderlands and i will kill you ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>im coming on borderlands and i will murder you...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>im getting on borderlands 2 and i will murder ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sentiment                                    cleaned_content\n",
       "0          1  im getting on borderlands and i will murder yo...\n",
       "1          1  I am coming to the borders and I will kill you...\n",
       "2          1  im getting on borderlands and i will kill you ...\n",
       "3          1  im coming on borderlands and i will murder you...\n",
       "4          1  im getting on borderlands 2 and i will murder ..."
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df4.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0d9b017f-ae53-41d4-baa6-734270a67a56",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sentiment\n",
       "0    22358\n",
       "1    20655\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df4[\"sentiment\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "36332496-54b8-435e-8300-97584b3d778b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X = df4.drop('sentiment', axis=1)\n",
    "y = df4[\"sentiment\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd229018-35d7-4c68-97d0-e0608a52816c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Train-Test Split with Stratification to maintain class distribution\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "93644258-5119-4969-bc90-512d1e64a07d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sentiment\n",
       "0    17886\n",
       "1    16524\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8132942c",
   "metadata": {},
   "source": [
    "## Model Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "561c69ff-9104-48da-a165-43a235406fbf",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-05 08:11:49.573463: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-10-05 08:11:49.582428: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-10-05 08:11:49.582428: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-10-05 08:11:49.586683: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-10-05 08:11:49.586683: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-10-05 08:11:49.586683: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-10-05 08:11:49.906639: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-10-05 08:11:49.906639: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-10-05 08:11:49.906639: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-10-05 08:11:49.906639: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 15657 MB memory:  -> device: 0, name: Quadro P5000, pci bus id: 0000:00:05.0, compute capability: 6.1\n",
      "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFDistilBertForSequenceClassification: ['vocab_layer_norm.bias', 'vocab_transform.weight', 'vocab_transform.bias', 'vocab_projector.bias', 'vocab_layer_norm.weight']\n",
      "- This IS expected if you are initializing TFDistilBertForSequenceClassification from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFDistilBertForSequenceClassification from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights or buffers of the TF 2.0 model TFDistilBertForSequenceClassification were not initialized from the PyTorch model and are newly initialized: ['pre_classifier.weight', 'pre_classifier.bias', 'classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded distilbert-base-uncased for full fine-tuning. Total trainable parameters:\n",
      "Model: \"tf_distil_bert_for_sequence_classification\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " distilbert (TFDistilBertMa  multiple                  66362880  \n",
      " inLayer)                                                        \n",
      "                                                                 \n",
      " pre_classifier (Dense)      multiple                  590592    \n",
      "                                                                 \n",
      " classifier (Dense)          multiple                  1538      \n",
      "                                                                 \n",
      " dropout_19 (Dropout)        multiple                  0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66955010 (255.41 MB)\n",
      "Trainable params: 66955010 (255.41 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 1. Load the DistilBertTokenizer model from Hugging Face \n",
    "tokenizer = DistilBertTokenizerFast.from_pretrained(MODEL_NAME)\n",
    "\n",
    "# 2. Load the TFDistilBertForSequenceClassification classification model since it is lightweight and fast\n",
    "# `from_pretrained` loads the model with pre-trained weights\n",
    "model = TFDistilBertForSequenceClassification.from_pretrained(\n",
    "    MODEL_NAME, \n",
    "    num_labels=NUM_LABELS\n",
    ")\n",
    "\n",
    "print(f\"Loaded {MODEL_NAME} for full fine-tuning. Total trainable parameters:\")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7948d24-ca7e-4cd6-bcb5-b6c290293c42",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Tokenization of training data\n",
    "\n",
    "tokenized = tokenizer.batch_encode_plus(\n",
    "    X_train[\"cleaned_content\"].tolist(),\n",
    "    padding=True,          # pad to longest sentence\n",
    "    truncation=True,       # truncate longer sentences\n",
    "    return_tensors=\"tf\"    # return as tensorflow tensors\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "061c14f9-daf1-4f85-a599-35d5e83a455f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(34410, 315), dtype=int32, numpy=\n",
       "array([[  101, 14601,  3111, ...,     0,     0,     0],\n",
       "       [  101,  1045,  1521, ...,     0,     0,     0],\n",
       "       [  101,  1030, 19413, ...,     0,     0,     0],\n",
       "       ...,\n",
       "       [  101,  1030, 19413, ...,     0,     0,     0],\n",
       "       [  101,  7632,  1010, ...,     0,     0,     0],\n",
       "       [  101,  1039,  1005, ...,     0,     0,     0]], dtype=int32)>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized[\"input_ids\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ab9272c-1356-4202-b064-0926e01213da",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Decoding the tokenized input ids back to text to verify correctness\n",
    "\n",
    "tokenizer.batch_decode(tokenized[\"input_ids\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c0bf6d0-ab1c-452c-8486-a36ace06b78e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "val_dataset = pd.read_csv(\"twitter_validation.csv\") # Reading the validation dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6dc9df81-7319-41f4-be56-abe69d400184",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweet ID</th>\n",
       "      <th>entity</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>Tweet content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3364</td>\n",
       "      <td>Facebook</td>\n",
       "      <td>Irrelevant</td>\n",
       "      <td>I mentioned on Facebook that I was struggling ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>352</td>\n",
       "      <td>Amazon</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>BBC News - Amazon boss Jeff Bezos rejects clai...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8312</td>\n",
       "      <td>Microsoft</td>\n",
       "      <td>Negative</td>\n",
       "      <td>@Microsoft Why do I pay for WORD when it funct...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4371</td>\n",
       "      <td>CS-GO</td>\n",
       "      <td>Negative</td>\n",
       "      <td>CSGO matchmaking is so full of closet hacking,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4433</td>\n",
       "      <td>Google</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>Now the President is slapping Americans in the...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Tweet ID     entity   sentiment  \\\n",
       "0      3364   Facebook  Irrelevant   \n",
       "1       352     Amazon     Neutral   \n",
       "2      8312  Microsoft    Negative   \n",
       "3      4371      CS-GO    Negative   \n",
       "4      4433     Google     Neutral   \n",
       "\n",
       "                                       Tweet content  \n",
       "0  I mentioned on Facebook that I was struggling ...  \n",
       "1  BBC News - Amazon boss Jeff Bezos rejects clai...  \n",
       "2  @Microsoft Why do I pay for WORD when it funct...  \n",
       "3  CSGO matchmaking is so full of closet hacking,...  \n",
       "4  Now the President is slapping Americans in the...  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f22d775-a0cc-4948-96f4-1457b581f2dc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Encode the sentiment labels to numerical values\n",
    "val_dataset[\"sentiment\"].replace({\n",
    "    \"Negative\": 0,\n",
    "    \"Positive\": 1,\n",
    "},\n",
    "inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "918034c7-67ce-4f1b-963b-e554698a3917",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "# --- 1. Noise Removal Function ---\n",
    "def clean_tweet_text(text):\n",
    "    # Remove URLs/Links (http, https, www, pic.twitter.com)\n",
    "    text = re.sub(r'http\\S+|www\\S+|pic\\.twitter\\.com\\S+', '', text, flags=re.MULTILINE)\n",
    "    # Remove Twitter Handles (@username)\n",
    "    text = re.sub(r'@\\w+', '', text)\n",
    "    # Remove Retweet tags (if any)\n",
    "    text = re.sub(r'RT\\s+', '', text)\n",
    "    # Remove extra whitespace\n",
    "    text = ' '.join(text.split()).strip()\n",
    "    return text\n",
    "\n",
    "# Apply the cleaning function\n",
    "val_dataset['cleaned_content'] = val_dataset['Tweet content'].apply(clean_tweet_text)\n",
    "val_dataset.drop(['Tweet content'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d97b5d05-ee0e-42d6-87e0-0e5f5751fcd3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Drop the 'Irrelevant' Class\n",
    "val_dataset_filtered = val_dataset[val_dataset['sentiment'] != 'Irrelevant'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48b9f34d-b701-4392-ba10-89b37cb5613b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Drop the 'Neutral' Class\n",
    "val_dataset_filtered = val_dataset_filtered[val_dataset_filtered['sentiment'] != 'Neutral'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0ba1ef3-d7e8-4cb0-86fe-3654bfe0f226",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "val_dataset_filtered.drop(['Tweet ID', 'entity'], axis=1, inplace=True) # Dropping unnecessary columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ae4f92a3-03de-4a10-921b-e50445db0f35",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sentiment\n",
       "1    277\n",
       "0    266\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_dataset_filtered[\"sentiment\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "fe81cfb1-0069-459e-9388-b53f66a87b8a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "training_labels = tf.constant(y_train, dtype=tf.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "93575e37-c3bb-41b0-9773-4e9c7f30bb1c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_val = val_dataset_filtered[\"cleaned_content\"]\n",
    "y_val = val_dataset_filtered[\"sentiment\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1020108e-edad-4459-9377-5a0a5e2707fa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "val_labels = tf.constant(y_val, dtype=tf.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eea691fa-521d-46de-88ca-b22e845be3b7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Tokenization of validation data\n",
    "val_tokenized = tokenizer.batch_encode_plus(\n",
    "    X_val.tolist(),\n",
    "    padding=True,          # pad to longest sentence\n",
    "    truncation=True,       # truncate longer sentences\n",
    "    return_tensors=\"tf\"    # return as tensorflow tensors\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4495810-b561-45c3-b5bf-3865652b6811",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "# Create a dictionary of the tokenized inputs\n",
    "tokenized_inputs = {\n",
    "    'input_ids': tokenized['input_ids'], \n",
    "    'attention_mask': tokenized['attention_mask']\n",
    "}\n",
    "\n",
    "# Create a tf.data.Dataset from the full inputs\n",
    "# Apply batching (e.g., in chunks of 32)\n",
    "feature_extraction_dataset = tf.data.Dataset.from_tensor_slices(tokenized_inputs).batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39b795bb-cd0d-4f11-b0a0-aab29b69d7ad",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "all_pooled_outputs = []\n",
    "\n",
    "# Loop through the batched dataset\n",
    "for batch_inputs in feature_extraction_dataset:\n",
    "    \n",
    "    # Run the model's base layer on the small batch\n",
    "    batch_outputs = model.distilbert(\n",
    "        input_ids=batch_inputs['input_ids'], \n",
    "        attention_mask=batch_inputs['attention_mask'], \n",
    "        training=False # Set training to False for inference\n",
    "    )\n",
    "    \n",
    "    # Get the [CLS] token's hidden state\n",
    "    last_hidden_state = batch_outputs.last_hidden_state\n",
    "    batch_pooled_output = last_hidden_state[:, 0, :]\n",
    "    \n",
    "    # Store the result\n",
    "    all_pooled_outputs.append(batch_pooled_output.numpy())\n",
    "\n",
    "# Concatenate all batches to get the final full pooled output array\n",
    "pooled_output = np.concatenate(all_pooled_outputs, axis=0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6276f9c",
   "metadata": {},
   "source": [
    "## Building custom classifier from distillbert model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "241ed281-2ecb-4ed4-9674-1639598a5844",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.models import Model\n",
    "# Assuming 'base_model' is your loaded TFDistilBertForSequenceClassification object\n",
    "# and 'NUM_LABELS' is the number of classes (e.g., 4)\n",
    "\n",
    "DROPOUT_RATE = 0.4  # Add a regularization rate\n",
    "\n",
    "def build_custom_classifier(base_model, num_labels, dropout_rate=0.2):\n",
    "    # 1. Get the DistilBERT base layer's input tensors\n",
    "    input_ids = tf.keras.layers.Input(shape=(None,), dtype=tf.int32, name='input_ids')\n",
    "    attention_mask = tf.keras.layers.Input(shape=(None,), dtype=tf.int32, name='attention_mask')\n",
    "    \n",
    "    # 2. Pass inputs to the DistilBERT base model\n",
    "    # Note: We access the 'distilbert' layer inside the TFDistilBertForSequenceClassification object\n",
    "    outputs = base_model.distilbert(\n",
    "        input_ids=input_ids,\n",
    "        attention_mask=attention_mask\n",
    "    )\n",
    "    \n",
    "    # 3. Get the pooled output: the hidden state of the [CLS] token (index 0)\n",
    "    pooled_output = outputs.last_hidden_state[:, 0, :]\n",
    "    \n",
    "    # 4. Add the Dropout layer for regularization\n",
    "    dropout_output = Dropout(dropout_rate, name=\"classifier_dropout\")(pooled_output)\n",
    "    \n",
    "    # 5. Add your custom adapter layer\n",
    "    adapter = Dense(64, activation=\"relu\", name=\"adapter_dense\")(dropout_output)\n",
    "    \n",
    "    # 6. Final Classification Layer\n",
    "    classification_output = Dense(num_labels, name=\"classification_output\")(adapter)\n",
    "    \n",
    "    # 7. Create the final Keras Model\n",
    "    final_model = Model(\n",
    "        inputs=[input_ids, attention_mask], \n",
    "        outputs=classification_output\n",
    "    )\n",
    "    \n",
    "    return final_model\n",
    "\n",
    "# Re-create the model using this function (assuming base_model and NUM_LABELS are defined)\n",
    "model = build_custom_classifier(model, NUM_LABELS, DROPOUT_RATE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fcce446",
   "metadata": {},
   "source": [
    "## Early stopping and Model checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96543bac-e067-4b2b-94b5-ceeca5ce019e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "early_stopping = EarlyStopping(monitor=\"val_loss\", patience=3, restore_best_weights=True)\n",
    "model_checkpoint = ModelCheckpoint(\n",
    "    filepath='final_high_accuracy_weights.h5', \n",
    "    monitor='val_loss', \n",
    "    save_best_only=True,\n",
    "    save_format=\"tf\" # Use the SavedModel format\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "961d12d0-f867-4913-aa24-ce218db54f35",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Instead of fully finetuning, freeze the core DistilBERT layer weights and only train the custom layers\n",
    "# We are doing frozen weights training to prevent overfitting and speed up training\n",
    "# This is especially useful when the dataset is small or when computational resources are limited\n",
    "\n",
    "model.get_layer('distilbert').trainable = False \n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "learning_rate = LEARNING_RATE\n",
    "optimizer = tf.keras.optimizers.AdamW(weight_decay=0.0001, learning_rate=learning_rate)\n",
    "loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "\n",
    "model.compile(\n",
    "    optimizer=optimizer,\n",
    "    loss=loss_fn,\n",
    "    metrics=['accuracy']\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d242d29-b85b-4abf-bd41-579d96b5c039",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_train dtype successfully cast to: int32\n",
      "y_val dtype successfully cast to: int32\n",
      "y_train shape: (34410,)\n",
      "y_val shape: (543,)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Explicitly convert the labels to np.int32\n",
    "y_train = np.array(y_train, dtype=np.int32)\n",
    "y_val = np.array(y_val, dtype=np.int32)\n",
    "\n",
    "print(f\"y_train dtype successfully cast to: {y_train.dtype}\")\n",
    "print(f\"y_val dtype successfully cast to: {y_val.dtype}\")\n",
    "\n",
    "# The dimensions of the labels might also be an issue.\n",
    "# SparseCategoricalCrossentropy often expects a flat array shape (N_samples,)\n",
    "# If your arrays have shape (N_samples, 1), try flattening them:\n",
    "if y_train.ndim > 1 and y_train.shape[1] == 1:\n",
    "    y_train = y_train.flatten()\n",
    "    y_val = y_val.flatten()\n",
    "\n",
    "print(f\"y_train shape: {y_train.shape}\")\n",
    "print(f\"y_val shape: {y_val.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00d3f982",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cd8d323-d59d-41b5-821f-42b582e9a89d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting FINAL training run using the correct Keras tuple structure...\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-05 08:20:19.204683: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:191] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
      "2025-10-05 08:20:20.247121: I external/local_xla/xla/service/service.cc:168] XLA service 0x7fdf0d0da2c0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2025-10-05 08:20:20.247210: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (0): Quadro P5000, Compute Capability 6.1\n",
      "2025-10-05 08:20:20.255197: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2025-10-05 08:20:20.279293: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8902\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1759652420.399017    3871 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1076/1076 [==============================] - ETA: 0s - loss: 0.5487 - accuracy: 0.7194WARNING:tensorflow:Skipping full serialization of Keras layer <keras.src.layers.regularization.dropout.Dropout object at 0x7fdfb5649ed0>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.src.layers.regularization.dropout.Dropout object at 0x7fdfb5648a10>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.src.layers.regularization.dropout.Dropout object at 0x7fdfb5bf8e90>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.src.layers.regularization.dropout.Dropout object at 0x7fdfb5690dd0>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.src.layers.regularization.dropout.Dropout object at 0x7fe05c8ac290>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.src.layers.regularization.dropout.Dropout object at 0x7fdfb56bb710>, because it is not built.\n",
      "INFO:tensorflow:Assets written to: best_frozen_model_weights_stable/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: best_frozen_model_weights_stable/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1076/1076 [==============================] - 369s 335ms/step - loss: 0.5487 - accuracy: 0.7194 - val_loss: 0.4365 - val_accuracy: 0.8066\n",
      "Epoch 2/20\n",
      "1076/1076 [==============================] - ETA: 0s - loss: 0.4859 - accuracy: 0.7708WARNING:tensorflow:Skipping full serialization of Keras layer <keras.src.layers.regularization.dropout.Dropout object at 0x7fdfb5649ed0>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.src.layers.regularization.dropout.Dropout object at 0x7fdfb5649ed0>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.src.layers.regularization.dropout.Dropout object at 0x7fdfb5648a10>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.src.layers.regularization.dropout.Dropout object at 0x7fdfb5648a10>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.src.layers.regularization.dropout.Dropout object at 0x7fdfb5bf8e90>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.src.layers.regularization.dropout.Dropout object at 0x7fdfb5bf8e90>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.src.layers.regularization.dropout.Dropout object at 0x7fdfb5690dd0>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.src.layers.regularization.dropout.Dropout object at 0x7fdfb5690dd0>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.src.layers.regularization.dropout.Dropout object at 0x7fe05c8ac290>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.src.layers.regularization.dropout.Dropout object at 0x7fe05c8ac290>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.src.layers.regularization.dropout.Dropout object at 0x7fdfb56bb710>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.src.layers.regularization.dropout.Dropout object at 0x7fdfb56bb710>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: best_frozen_model_weights_stable/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: best_frozen_model_weights_stable/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1076/1076 [==============================] - 358s 333ms/step - loss: 0.4859 - accuracy: 0.7708 - val_loss: 0.4345 - val_accuracy: 0.8122\n",
      "Epoch 3/20\n",
      "1076/1076 [==============================] - ETA: 0s - loss: 0.4778 - accuracy: 0.7731WARNING:tensorflow:Skipping full serialization of Keras layer <keras.src.layers.regularization.dropout.Dropout object at 0x7fdfb5649ed0>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.src.layers.regularization.dropout.Dropout object at 0x7fdfb5649ed0>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.src.layers.regularization.dropout.Dropout object at 0x7fdfb5648a10>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.src.layers.regularization.dropout.Dropout object at 0x7fdfb5648a10>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.src.layers.regularization.dropout.Dropout object at 0x7fdfb5bf8e90>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.src.layers.regularization.dropout.Dropout object at 0x7fdfb5bf8e90>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.src.layers.regularization.dropout.Dropout object at 0x7fdfb5690dd0>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.src.layers.regularization.dropout.Dropout object at 0x7fdfb5690dd0>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.src.layers.regularization.dropout.Dropout object at 0x7fe05c8ac290>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.src.layers.regularization.dropout.Dropout object at 0x7fe05c8ac290>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.src.layers.regularization.dropout.Dropout object at 0x7fdfb56bb710>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.src.layers.regularization.dropout.Dropout object at 0x7fdfb56bb710>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: best_frozen_model_weights_stable/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: best_frozen_model_weights_stable/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1076/1076 [==============================] - 358s 333ms/step - loss: 0.4778 - accuracy: 0.7731 - val_loss: 0.4227 - val_accuracy: 0.8232\n",
      "Epoch 4/20\n",
      "1076/1076 [==============================] - 349s 325ms/step - loss: 0.4727 - accuracy: 0.7791 - val_loss: 0.4333 - val_accuracy: 0.8250\n",
      "Epoch 5/20\n",
      "1076/1076 [==============================] - ETA: 0s - loss: 0.4728 - accuracy: 0.7798WARNING:tensorflow:Skipping full serialization of Keras layer <keras.src.layers.regularization.dropout.Dropout object at 0x7fdfb5649ed0>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.src.layers.regularization.dropout.Dropout object at 0x7fdfb5649ed0>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.src.layers.regularization.dropout.Dropout object at 0x7fdfb5648a10>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.src.layers.regularization.dropout.Dropout object at 0x7fdfb5648a10>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.src.layers.regularization.dropout.Dropout object at 0x7fdfb5bf8e90>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.src.layers.regularization.dropout.Dropout object at 0x7fdfb5bf8e90>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.src.layers.regularization.dropout.Dropout object at 0x7fdfb5690dd0>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.src.layers.regularization.dropout.Dropout object at 0x7fdfb5690dd0>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.src.layers.regularization.dropout.Dropout object at 0x7fe05c8ac290>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.src.layers.regularization.dropout.Dropout object at 0x7fe05c8ac290>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.src.layers.regularization.dropout.Dropout object at 0x7fdfb56bb710>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.src.layers.regularization.dropout.Dropout object at 0x7fdfb56bb710>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: best_frozen_model_weights_stable/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: best_frozen_model_weights_stable/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1076/1076 [==============================] - 357s 332ms/step - loss: 0.4728 - accuracy: 0.7798 - val_loss: 0.4023 - val_accuracy: 0.8250\n",
      "Epoch 6/20\n",
      "1076/1076 [==============================] - 348s 323ms/step - loss: 0.4716 - accuracy: 0.7781 - val_loss: 0.4049 - val_accuracy: 0.8195\n",
      "Epoch 7/20\n",
      "1076/1076 [==============================] - ETA: 0s - loss: 0.4686 - accuracy: 0.7780WARNING:tensorflow:Skipping full serialization of Keras layer <keras.src.layers.regularization.dropout.Dropout object at 0x7fdfb5649ed0>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.src.layers.regularization.dropout.Dropout object at 0x7fdfb5649ed0>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.src.layers.regularization.dropout.Dropout object at 0x7fdfb5648a10>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.src.layers.regularization.dropout.Dropout object at 0x7fdfb5648a10>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.src.layers.regularization.dropout.Dropout object at 0x7fdfb5bf8e90>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.src.layers.regularization.dropout.Dropout object at 0x7fdfb5bf8e90>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.src.layers.regularization.dropout.Dropout object at 0x7fdfb5690dd0>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.src.layers.regularization.dropout.Dropout object at 0x7fdfb5690dd0>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.src.layers.regularization.dropout.Dropout object at 0x7fe05c8ac290>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.src.layers.regularization.dropout.Dropout object at 0x7fe05c8ac290>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.src.layers.regularization.dropout.Dropout object at 0x7fdfb56bb710>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.src.layers.regularization.dropout.Dropout object at 0x7fdfb56bb710>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: best_frozen_model_weights_stable/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: best_frozen_model_weights_stable/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1076/1076 [==============================] - 358s 333ms/step - loss: 0.4686 - accuracy: 0.7780 - val_loss: 0.3985 - val_accuracy: 0.8306\n",
      "Epoch 8/20\n",
      "1076/1076 [==============================] - 348s 323ms/step - loss: 0.4688 - accuracy: 0.7820 - val_loss: 0.4064 - val_accuracy: 0.8250\n",
      "Epoch 9/20\n",
      "1076/1076 [==============================] - 348s 324ms/step - loss: 0.4644 - accuracy: 0.7826 - val_loss: 0.4094 - val_accuracy: 0.8287\n",
      "Epoch 10/20\n",
      "1076/1076 [==============================] - ETA: 0s - loss: 0.4670 - accuracy: 0.7810WARNING:tensorflow:Skipping full serialization of Keras layer <keras.src.layers.regularization.dropout.Dropout object at 0x7fdfb5649ed0>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.src.layers.regularization.dropout.Dropout object at 0x7fdfb5649ed0>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.src.layers.regularization.dropout.Dropout object at 0x7fdfb5648a10>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.src.layers.regularization.dropout.Dropout object at 0x7fdfb5648a10>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.src.layers.regularization.dropout.Dropout object at 0x7fdfb5bf8e90>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.src.layers.regularization.dropout.Dropout object at 0x7fdfb5bf8e90>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.src.layers.regularization.dropout.Dropout object at 0x7fdfb5690dd0>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.src.layers.regularization.dropout.Dropout object at 0x7fdfb5690dd0>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.src.layers.regularization.dropout.Dropout object at 0x7fe05c8ac290>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.src.layers.regularization.dropout.Dropout object at 0x7fe05c8ac290>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.src.layers.regularization.dropout.Dropout object at 0x7fdfb56bb710>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.src.layers.regularization.dropout.Dropout object at 0x7fdfb56bb710>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: best_frozen_model_weights_stable/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: best_frozen_model_weights_stable/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1076/1076 [==============================] - 358s 333ms/step - loss: 0.4670 - accuracy: 0.7810 - val_loss: 0.3909 - val_accuracy: 0.8379\n",
      "Epoch 11/20\n",
      "1076/1076 [==============================] - 347s 322ms/step - loss: 0.4670 - accuracy: 0.7844 - val_loss: 0.4152 - val_accuracy: 0.8250\n",
      "Epoch 12/20\n",
      "1076/1076 [==============================] - ETA: 0s - loss: 0.4636 - accuracy: 0.7846WARNING:tensorflow:Skipping full serialization of Keras layer <keras.src.layers.regularization.dropout.Dropout object at 0x7fdfb5649ed0>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.src.layers.regularization.dropout.Dropout object at 0x7fdfb5649ed0>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.src.layers.regularization.dropout.Dropout object at 0x7fdfb5648a10>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.src.layers.regularization.dropout.Dropout object at 0x7fdfb5648a10>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.src.layers.regularization.dropout.Dropout object at 0x7fdfb5bf8e90>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.src.layers.regularization.dropout.Dropout object at 0x7fdfb5bf8e90>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.src.layers.regularization.dropout.Dropout object at 0x7fdfb5690dd0>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.src.layers.regularization.dropout.Dropout object at 0x7fdfb5690dd0>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.src.layers.regularization.dropout.Dropout object at 0x7fe05c8ac290>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.src.layers.regularization.dropout.Dropout object at 0x7fe05c8ac290>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.src.layers.regularization.dropout.Dropout object at 0x7fdfb56bb710>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.src.layers.regularization.dropout.Dropout object at 0x7fdfb56bb710>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: best_frozen_model_weights_stable/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: best_frozen_model_weights_stable/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1076/1076 [==============================] - 358s 333ms/step - loss: 0.4636 - accuracy: 0.7846 - val_loss: 0.3899 - val_accuracy: 0.8269\n",
      "Epoch 13/20\n",
      "1076/1076 [==============================] - 348s 323ms/step - loss: 0.4614 - accuracy: 0.7848 - val_loss: 0.4082 - val_accuracy: 0.8306\n",
      "Epoch 14/20\n",
      "1076/1076 [==============================] - 348s 324ms/step - loss: 0.4594 - accuracy: 0.7871 - val_loss: 0.4165 - val_accuracy: 0.8306\n",
      "Epoch 15/20\n",
      "1076/1076 [==============================] - 348s 323ms/step - loss: 0.4600 - accuracy: 0.7856 - val_loss: 0.3934 - val_accuracy: 0.8306\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 1. Define the input features as a tuple (features are always first)\n",
    "train_inputs_tuple = (tokenized['input_ids'], tokenized['attention_mask'])\n",
    "\n",
    "# 2. Define the validation data as a tuple (inputs, labels)\n",
    "val_data_tuple = ((val_tokenized['input_ids'], val_tokenized['attention_mask']), y_val)\n",
    "\n",
    "print(\"Starting FINAL training run using the correct Keras tuple structure...\")\n",
    "\n",
    "history = model.fit(\n",
    "    # Pass the inputs as a tuple and labels separately for validation dataset\n",
    "    x=train_inputs_tuple, \n",
    "    y=y_train,\n",
    "    epochs=EPOCHS, \n",
    "    batch_size=BATCH_SIZE, \n",
    "    validation_data=val_data_tuple,\n",
    "    callbacks=[early_stopping, model_checkpoint] \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1f2ef25",
   "metadata": {},
   "source": [
    "## Loading the best model saved from the model checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23f171fb-b078-40d1-bb1c-739ee7f8799c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-05 10:04:05.976497: W tensorflow/core/util/tensor_slice_reader.cc:98] Could not open best_frozen_model_weights_stable: DATA_LOSS: file is too short to be an sstable: perhaps your file is in a different file format and you need to use a different restore operator?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best weights successfully loaded (using load_weights).\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import numpy as np\n",
    "\n",
    "# --- 1. Load ONLY the Weights into the Re-created Model Structure ---\n",
    "LOAD_PATH = 'final_high_accuracy_weights.h5' \n",
    "# Assuming your re-created model is named 'model' from the definition cell\n",
    "model.load_weights(LOAD_PATH) \n",
    "best_model = model # Use the re-created model with loaded weights\n",
    "\n",
    "print(\"Best weights successfully loaded (using load_weights).\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7c2c7a0",
   "metadata": {},
   "source": [
    "## Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b2a7338-a19d-4e57-808e-95d2c979d42e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Running Final Evaluation on UNSEEN Test Data ---\n",
      "\n",
      "Final Test Loss: 0.4219\n",
      "Final Test Accuracy: 0.8097\n"
     ]
    }
   ],
   "source": [
    "# ---  Tokenize the Test Set ---\n",
    "X_test_text = X_test[\"cleaned_content\"].tolist()\n",
    "y_test_np = np.array(y_test, dtype=np.int32) # Ensure labels are correct dtype\n",
    "\n",
    "test_tokenized = tokenizer.batch_encode_plus(\n",
    "    X_test_text,\n",
    "    padding=True,          \n",
    "    truncation=True,       \n",
    "    return_tensors=\"tf\"    \n",
    ")\n",
    "\n",
    "# --- Format the Test Data for Keras ---\n",
    "test_data_tuple = (\n",
    "    (test_tokenized['input_ids'], test_tokenized['attention_mask']), \n",
    "    y_test_np\n",
    ")\n",
    "\n",
    "# --- Run the Final Evaluation on the Test Set ---\n",
    "\n",
    "print(\"--- Running Final Evaluation on UNSEEN Test Data ---\")\n",
    "\n",
    "loss, accuracy = best_model.evaluate(\n",
    "    x=test_data_tuple[0], \n",
    "    y=test_data_tuple[1], \n",
    "    verbose=0\n",
    ")\n",
    "\n",
    "print(f\"\\nFinal Test Loss: {loss:.4f}\")\n",
    "print(f\"Final Test Accuracy: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9051506c",
   "metadata": {},
   "source": [
    "## Evaluation Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8f3086f-4731-4f6a-a895-bbc5e7c25aa1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "269/269 [==============================] - 73s 272ms/step\n",
      "\n",
      "Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8056    0.8356    0.8203      4472\n",
      "           1     0.8146    0.7817    0.7978      4131\n",
      "\n",
      "    accuracy                         0.8097      8603\n",
      "   macro avg     0.8101    0.8086    0.8091      8603\n",
      "weighted avg     0.8099    0.8097    0.8095      8603\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "\n",
      "[[3737  735]\n",
      " [ 902 3229]]\n"
     ]
    }
   ],
   "source": [
    "# --- Prepare the Test Data (Using your existing code, which is correct) ---\n",
    "test_labels = tf.constant(y_test, dtype=tf.int32)\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((dict(test_tokenized), test_labels)) \\\n",
    "             .batch(32) \n",
    "\n",
    "# ---  Get predictions (logits) from the model ---\n",
    "# Note: For Hugging Face TF models, predictions often require the .logits attribute.\n",
    "# We will use a try-except block to handle both output types safely.\n",
    "y_pred_logits = best_model.predict(test_dataset)\n",
    "\n",
    "# ---  Convert logits to predicted class labels ---\n",
    "try:\n",
    "    # Try the Hugging Face output format (where logits is an attribute)\n",
    "    y_pred = np.argmax(y_pred_logits.logits, axis=1)\n",
    "except AttributeError:\n",
    "    # Fall back to the standard Keras output format\n",
    "    y_pred = np.argmax(y_pred_logits, axis=1)\n",
    "\n",
    "# ---  Get true labels ---\n",
    "y_true = np.concatenate([y for x, y in test_dataset], axis=0) \n",
    "\n",
    "# ---  Print results ---\n",
    "print(\"\\nClassification Report:\\n\")\n",
    "print(classification_report(y_true, y_pred, digits=4))\n",
    "print(\"\\nConfusion Matrix:\\n\")\n",
    "print(confusion_matrix(y_true, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
